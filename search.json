[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "About\n\n\n\nMy name is Paul Beard. I am a technical orientated Fellow of the Institute of Actuaries working in the life insurance industry for over 12 years, with over 7 of those years being post qualification.\nI am also experienced as an R developer and have built complex models, complete packages and everything on this website.\nThe combination of these skills allows me to build end-to-end actuarial workflows that could be used to upgrade your company. There has never been a better time to hire my expertise and take your actuarial systems to the next level."
  },
  {
    "objectID": "artificial_actuary_cod.html",
    "href": "artificial_actuary_cod.html",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "",
    "text": "Recently an actuarial colleague came across a problem. They wanted to categorise a dataset containing many irregular and free-text causes of death, into broader categories. This can be a problem for any actuary working in longevity, where we might want to apply stresses for the various drivers of mortality to a select subgroup of the population.\nBefore the AI overlords take over, and the only cause of mortality is simply “death by robot”, I wanted to see if LLMs could help with this classification problem."
  },
  {
    "objectID": "artificial_actuary_cod.html#the-aim",
    "href": "artificial_actuary_cod.html#the-aim",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "The Aim",
    "text": "The Aim\nUsing R, connect to the API of various LLMs and get them to perform the onerous task of classifying data for us. Can we get the LLMs to do a job that might have taken an actuary lots of time and effort? Can we do it in a way that is automatable, such that if circumstances change we simply press a button and update?"
  },
  {
    "objectID": "artificial_actuary_cod.html#the-premise",
    "href": "artificial_actuary_cod.html#the-premise",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "The Premise",
    "text": "The Premise\nFor this experiment I will get different LLMs to classify the ICD-10 causes of death into broader categories. The categories I have pulled from a paper online related to the cause-specific mortality impact of smoking. The paper and categories are not too important, they are just an example of what an actuary might be use. The following paper…\nCigarette Smoking Cessation, Total and Cause-specific Mortality: A 22-Year Follow-up Study in US Male Physicians\n…states that smoking showed an increase in mortality for the following categories of disease:\n\ncoronary heart disease\ncerebrovascular disease\npulmonary disease\nlung cancer\ncolorectal cancer\nlarynx cancer\nkidney cancer\nacute myeloid leukemia\noral cavity cancer\nesophageal cancer\npancreatic cancer\nbladder cancer\nstomach cancer\nprostate cancer\nsudden death\n\nThis paper would be very useful, but my other dataset is the ONS cause of death mortality by ICD-10 code in England and Wales. A snapshot of just some of those causes of death is shown below:\n\n\n\n\nTable 1: Random Sample of Causes of Death\n  \n    \n      Cause of Death\n      No of Deaths 2013 to 2023\n    \n  \n  \n    Cushing syndrome unspecified\n42\n    Benign neoplasm Appendix\n2\n    Other specified diseases of biliary tract\n34\n    Sarcoidosis of lung\n602\n    Primary pulmonary hypertension\n570\n    Malignant neoplasm Glans penis\n17\n    Other instability of joint\n1\n    Malignant neoplasm External upper lip\n10\n    Somatoform autonomic dysfunction\n2\n    Occupant [any] of heavy transport vehicle injured in other specified transport accidents\n1\n  \n  \n  \n\n\n\n\nThere are thousands listed. Each category in our smoking paper can cover many causes of death in the data set. Can an LLM figure which ones out so an actuary won’t have to?"
  },
  {
    "objectID": "artificial_actuary_cod.html#method",
    "href": "artificial_actuary_cod.html#method",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "Method",
    "text": "Method\nMy initial attempt at this tried to use the {mall} package and an LLM that I downloaded straight to my computer. It became apparent quite soon that the processing power of LLMs is enormous, and too much for my humble laptop.\nInstead, I have used the brilliant {ellmer} package. This package allows R users to connect to a whole range of APIs available. Spoilt for choice, I set up a few links. The following LLMs were used:\n\nChat GPT 4o (gpt-4o-2024-08-06)\nChat GPT 4o Mini (gpt-4o-mini-2024-07-18)\nGemini (gemini-2.0-flash-001)\nLlama (llama-3.3-70b-versatile)\nDeepseek R1, distilled (deepseek-r1-distill-llama-70b)\n\nInitial attempts revealed some of the problems with using LLMs to clean data.\nThe first issue was around token limits and speed. Sending a single cause of death at a time would be unlikely to trigger the limits of the API and has the benefit of data structure being more regular (see second issue). However it would take far too long, and would be inefficient with token use asking the same question for each single cause of death. On the opposite end of the spectrum, sending data in larger chunks can sometimes cause failure as token limits are reached for a request. They also create data structure problem as the LLM is now giving us multiple data points in one chat we must decode this and hope they haven’t gone off-the-wall. In the end the best solution was to chunk the data and send over in batches.\nThe second main issue was getting data back in a regular format. It was almost comical how badly behave some of the LLMs were at being regular. Sometimes the no. of results didn’t match the no. of items sent. It was also impossible to get Deepseek to stop explaining itself in the output - no matter what I told it in the prompt! In the end it became apparent the best strategy was to communicate in JSON format and get the key results wrapped up in markers so I can extract it from the text and convert back to a dataframe using jsonlite::fromJSON(). The initial prompt evolved over time. Below is what I sent in relation to structure:\n\n“You are a classification LLM. You will receive a JSON file. The file will contain a list of items with cause_of_death. It is important that you return only an edited version of the JSON file. Add ‘category’ to each item, which can only ever pick one of the values below. No explanations. Return only the data in a structured JSON format. Your final JSON code must begin with ``` and end with ```”\n\nThe final issue was ambiguity. Some of the categories in the smoking paper could be interpreted in different ways. For example “pulmonary disease” technically means any disease of the lungs, yet this could entail something completely disconnected to smoking, such as tuberculosis with HIV or asbestos poisoning. Genetic disorders are also not going to be relevant to our risk driver in this case. In the end, I added further instruction to my LLM prompt:\n\n“If a cause of death cannot be linked to smoking in any way, for example if it is an infectious disease, a genetic disorder, or has an external cause provided in the cause_of_death text (e.g. asbestos), then assign the category as”none””\n\nThis didn’t eliminate some ambiguity over some of the groups. In particular, the terms “sudden death” and “coronary heart disease” weren’t clear to me what they entailed precisely. Given I was hoping to mark the results, I dropped “sudden death” and changed to “ischaemic heart disease” respectively.\nFinally, before I fed the causes of death into the LLM, I shuffled them. My original dataset was already ordered in a way that hinted at its groups. This was very handy for me when I had an attempt at categorising, but why should I give the robots the same privilege? By shuffling we prevent them getting wise to patterns, and demonstrate extra capability of the artificial actuary over the human actuary."
  },
  {
    "objectID": "artificial_actuary_cod.html#results",
    "href": "artificial_actuary_cod.html#results",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "Results",
    "text": "Results\nThere were 3,598 causes of death. I processed the category returned by each model, and compared to my own evaluation. A huge caveat here is that I am not a medical doctor, and have done the best with my very limited faculties. In general I have used the broader categorisation of ICD-10 codes that already exists.\nThe accuracy of every model was at least 93%. However because 3,353 of the causes of death fed in should not have been assigned a category, a score of 93% would also be attained by simply stating “none” for everything.\n\n\n\n\nTable 2: Accuracy and Completion Rates of LLMs\n  \n    \n    \n    \n  \n  \n    \n      Model\n      Accuracy\n      Proportion Answered\n    \n  \n  \n    unanimous_consensus\n99.6%\n88%\n    consensus\n97.6%\n100%\n    gpt_4o\n97.0%\n100%\n    deepseek_r1\n96.8%\n99%\n    gpt_4o_mini\n96.3%\n100%\n    gemini\n95.4%\n100%\n    llama_33\n93.3%\n100%\n  \n  \n  \n\n\n\n\nTo get a better understanding of the model success, we look at the stats of precision, recall and f1. A higher precision score means the model was often right when assigning a category (other than “none”). A higher recall score means the model did not often assign a category incorrectly (other than “none”). The F1 score combines these two to give an overall performance rating.\n\n\n\n\nTable 3: Performance Evaluation of LLMs\n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Model\n      \n        Count\n      \n      \n        Scores\n      \n    \n    \n      True Negative\n      False Negative\n      True Positive\n      False Positive\n      Precision\n      Recall\n      F1\n    \n  \n  \n    gpt_4o\n3282\n36\n190\n71\n73%\n84%\n78%\n    deepseek_r1\n3268\n53\n172\n62\n74%\n76%\n75%\n    gemini\n3219\n29\n197\n134\n60%\n87%\n71%\n    gpt_4o_mini\n3323\n103\n123\n29\n81%\n54%\n65%\n    llama_33\n3129\n18\n208\n222\n48%\n92%\n63%\n  \n  \n  \n\n\n\n\nWe can see that gpt_4o_mini is more reserved than the other models - only assigning a category to 132 causes of death. This results in the highest precision score, but a punishing recall score which leads it ranked near the bottom. Some of the mistakes made by gpt_4o_mini highlighted this over-cautiousness. For example the gpt_4o_mini model failed to class “intracerebral haemorrhage in brain stem” as a “cerebrovascular disease” which is probably one of the less ambiguous cases, and instead class it as “none”. There are many similar examples in the results data.\nWe can see that llama_33 had the opposite problem, assigning a category to 430 causes of death. This led to a great recall but poor precision, which ranked it last. Having looked through the individual results, it is clear to me that llama deserved its place at the bottom. It often assigned “{body part} cancer” to any disease with a corresponding body part. This led to many false positives which were fairly obvious. An example would be assigning “alcohol-induced acute pancreatitis” to “pancreatic cancer” which is clearly not appropriate given the prompt it was provided.\nGemini was also quite gung-ho, though faired better than llama.\nThe clear winners were gpt_4o and deepseek_r1. Looking through the differences, they were due to more ambiguous cases rather than clear error."
  },
  {
    "objectID": "artificial_actuary_cod.html#meta-results",
    "href": "artificial_actuary_cod.html#meta-results",
    "title": "Artificial Actuary: Classifying Causes of Death",
    "section": "Meta Results",
    "text": "Meta Results\nThe F1 scores attained were good, but not incredible. We are certainly not ready to hand the steering wheel over to our artificial friends just yet. But can we use the wisdom of crowds to boost our results further? I created two meta-models.\n“consensus” picks the most common category of the 5 models above\n“unanimous_consensus” picks the category that all 5 models agreed on, if they did not all agree it refrains from answering\nThe results are impressive, with “consensus” having strong scores, and “unanimous_consensus” having fantastic results. In all unanimous cases of differences, it was for the most ambiguous of categories, and I was no more sure of my own answer than the models. I could certainly have been persuaded that “unanimous_consensus” was the correct answer each time.\n\n\n\n\nTable 4: Performance Evaluation of Meta LLMs\n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n      Model\n      \n        Count\n      \n      \n        Scores\n      \n    \n    \n      True Negative\n      False Negative\n      True Positive\n      False Positive\n      Precision\n      Recall\n      F1\n    \n  \n  \n    unanimous_consensus\n3016\n10\n106\n3\n97%\n91%\n94%\n    consensus\n3303\n35\n191\n50\n79%\n85%\n82%\n  \n  \n  \n\n\n\n\nAlthough the pickiness of “unanimous_consensus” helped boost its scores, it came at a cost. This meta-model failed to provide a category for 444 causes of death, which was 12% of the data fed in. One could still say that 88% of our data was categorised with high accuracy is a great win, and the actuary now only has to deal with 444 cases instead of the overwhelming 3,500+.\nThe “consensus” meta-model actually returned an answer for every cause of death. There was never a split decision between the LLMs. This strategy would be a good way to go if we were adamant we didn’t want to review any of the data ourselves!\n\nConclusion\nAlthough many actuaries now ask questions of AI to help with their day-to-day work, using R it is possible to go further and integrate the AI into actuarial data processing and even models. I have provided just one use case here, but there are many more out there for the typical actuary.\nUsing one LLM is helpful. Using many is very helpful. We are not at a point where the artificial actuary can replace the human one yet. The LLMs cannot understand the broader context of the problem, and this was clear to me each time I had to alter the prompt to get things working.\nThis demonstration not only highlights the usefulness of AI, but the enhanced possibilities when working with the more modern actuarial coding languages like R and Python.\nIf you are interested in the complete results, they are collected in the interactive table below:\n\n\n\n\n\n\n \n\nThis article was written by Paul Beard and first published on February 13, 2025"
  }
]